{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OpenStreet Data Wrangling with Python and SQL\n",
    "### by Sergei Neviadomski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "### Map area: Pittsburgh, PA, United States\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/pittsburgh_pennsylvania/\n",
    "\n",
    "This map is of place where I currently live. I'd like to explore open-source map of this area, reveal some inconsistencies in data and contribute to its improvement on OpenStreetMap.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data auditing and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I want to solve typical problem of openstreen data.  That is street abbreviation inconsistency. I used regular expressions to catch this abbreviations and to build mapping for solving this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OSM file\n",
    "osm_file = \"pittsburgh_pennsylvania.osm\"\n",
    "\n",
    "# re function\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# Expected street types list\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\",\n",
    "            \"Square\", \"Lane\", \"Road\", \"Trail\", \"Parkway\", \"Commons\", \"Alley\",\n",
    "            \"Bridge\", \"Highway\", \"Circle\", \"Terrace\", \"Way\"]\n",
    "\n",
    "# Adding street names in dictionary by type\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "# Checking tag for street data content \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# Auditing file for different abbreviations of same street types \n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")    \n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'18': set(['PA 18', 'Route 18']),\n",
      " '19': set(['Route 19', 'US 19']),\n",
      " '202': set(['Wilkins Avenue #202']),\n",
      " '217': set(['217']),\n",
      " '228': set(['Pennsylvania 228', 'Pennylvania 228', 'State Route 228']),\n",
      " '30': set(['Route 30', 'State Route 30', 'U.S. 30']),\n",
      " '400': set(['West Kensinger Drive #400']),\n",
      " '51': set(['Route 51', 'State Route 51']),\n",
      " '519': set(['PA 519', 'Route 519']),\n",
      " '8': set(['Route 8']),\n",
      " '837': set(['Route 837']),\n",
      " '885': set(['Route 885']),\n",
      " '910': set(['Route 910']),\n",
      " 'Allegheny': set(['South Allegheny']),\n",
      " 'Allies': set(['Boulevard of the Allies']),\n",
      " 'Automotive': set(['California Automotive']),\n",
      " 'Av.': set(['Fifth Av.']),\n",
      " 'Ave': set(['5th Ave',\n",
      "             '6th Ave',\n",
      "             'Arlington Ave',\n",
      "             'Atlantic Ave',\n",
      "             'Center Ave',\n",
      "             'Centre Ave',\n",
      "             'Elizabeth Ave',\n",
      "             'Fifth Ave',\n",
      "             'Forbes Ave',\n",
      "             'Friendship Ave',\n",
      "             'Glenn Ave',\n",
      "             'Highland Ave',\n",
      "             'Liberty Ave',\n",
      "             'Lynnwood Ave',\n",
      "             'Morewood Ave',\n",
      "             'North Highland Ave',\n",
      "             'Romine Ave',\n",
      "             'S Highland Ave',\n",
      "             'S Millvale Ave',\n",
      "             'S Negley Ave',\n",
      "             'S. Aiken Ave',\n",
      "             'Shadeland Ave',\n",
      "             'Shady Ave',\n",
      "             'South Aiken Ave',\n",
      "             'University Ave']),\n",
      " 'Ave.': set(['4th Ave.',\n",
      "              '5th Ave.',\n",
      "              'Chartiers Ave.',\n",
      "              'Fifth Ave.',\n",
      "              'Macon Ave.',\n",
      "              'Murray Ave.',\n",
      "              'Romine Ave.']),\n",
      " 'Blvd': set(['Beechwood Blvd',\n",
      "              'Lysle Blvd',\n",
      "              'Pennsbury Blvd',\n",
      "              'Sunset Blvd',\n",
      "              'Washington Blvd']),\n",
      " 'Blvd.': set(['Ohio River Blvd.']),\n",
      " 'Brdg': set(['Swindell Brdg']),\n",
      " 'CT': set(['Highfield CT']),\n",
      " 'Center': set(['Quaker Village Shopping Center']),\n",
      " 'Connector': set(['John Scott Connector']),\n",
      " 'Cove': set(['Pheasant Cove']),\n",
      " 'Crossing': set(['Banbury Crossing']),\n",
      " 'Ct': set(['Imperial Ct', 'LaPlace Point Ct']),\n",
      " 'DR': set(['MIDWAY DR']),\n",
      " 'Dowling': set(['Dowling']),\n",
      " 'Dr': set(['Berwick Dr',\n",
      "            'Black Hawk Dr',\n",
      "            'Camden Dr',\n",
      "            'Corporate Dr',\n",
      "            'Douglas Dr',\n",
      "            'Eastminster Dr',\n",
      "            'Fox Ridge Farms Dr',\n",
      "            'Glengary Dr',\n",
      "            'Greyfriar Dr',\n",
      "            'Industry Dr',\n",
      "            'Kirkwall Dr',\n",
      "            'Selvin Dr']),\n",
      " 'Dr.': set(['Estates Dr.']),\n",
      " 'East': set(['Deer Park Drive East',\n",
      "              'Horseshoe Circle East',\n",
      "              'Squaw Run Road East',\n",
      "              'Waterfront Drive East',\n",
      "              'Waterman Road East']),\n",
      " 'Eisele': set(['Eisele']),\n",
      " 'End': set(['Trails End']),\n",
      " 'Entrance': set(['Towne Hall Entrance']),\n",
      " 'Expressway': set(['Mon/Fayette Expressway', 'Tri-Boro Expressway']),\n",
      " 'Extension': set(['Bowman Street Extension',\n",
      "                   'Brierly Lane Extension',\n",
      "                   'Broadway Avenue Extension',\n",
      "                   'Federal Street Extension',\n",
      "                   'Gulf Lab Road Extension',\n",
      "                   'Hookstown Road Extension',\n",
      "                   'Jacktown Road Extension',\n",
      "                   'Middle Road Extension',\n",
      "                   'Mount Troy Road Extension',\n",
      "                   'Thomas Street Extension',\n",
      "                   'Virginia Avenue Extension']),\n",
      " 'Harbor': set(['Boothbay Harbor',\n",
      "                'Marblehead Harbor',\n",
      "                'Mystic Harbor',\n",
      "                'Saybrook Harbor']),\n",
      " 'Harding': set(['Harding']),\n",
      " 'Heights': set(['Meadow Heights']),\n",
      " 'Hill': set(['Serenity Hill']),\n",
      " 'Hwy': set(['Perry Hwy']),\n",
      " 'Joanne': set(['Joanne']),\n",
      " 'Ln': set(['Meadow Park Ln', 'Mountain Trails Ln']),\n",
      " 'Lysle': set(['Lysle']),\n",
      " 'Maples': set(['The Maples']),\n",
      " 'Marshall': set(['Marshall']),\n",
      " 'Maurers': set(['Maurers']),\n",
      " 'McAleer': set(['McAleer']),\n",
      " 'North': set(['Freedom Drive North',\n",
      "               'Grandview Drive North',\n",
      "               'Lakeside Drive North',\n",
      "               'Randolph Drive North']),\n",
      " 'Oaks': set(['The Oaks']),\n",
      " 'PA-228': set(['PA-228']),\n",
      " 'PA-910': set(['PA-910']),\n",
      " 'PA-982': set(['PA-982']),\n",
      " 'Park': set(['Arlington Park', 'Blueberry Hill Park']),\n",
      " 'Patricia': set(['Patricia']),\n",
      " 'Penco': set(['Penco']),\n",
      " 'Pike': set(['Greensburg Pike',\n",
      "              'Kittanning Pike',\n",
      "              'Northern Pike',\n",
      "              'Steubenville Pike',\n",
      "              'Washington Pike']),\n",
      " 'Pl': set(['Washington Pl']),\n",
      " 'Plaza': set(['Penn Plaza']),\n",
      " 'Rd': set(['Bayard Rd',\n",
      "            'Browns Hill Rd',\n",
      "            'Brownsville Rd',\n",
      "            'California Rd',\n",
      "            'Camp Hollow Rd',\n",
      "            'Hill-Church Houston Rd',\n",
      "            'Kerrwood Rd',\n",
      "            'McNeilly Rd',\n",
      "            'Ravencrest Rd',\n",
      "            'Robinhood Rd',\n",
      "            'State Line Rd',\n",
      "            'Wexford Rd']),\n",
      " 'Rear': set(['Spruce Street Rear']),\n",
      " 'Rossway': set(['Rossway']),\n",
      " 'Run': set(['Honey Run']),\n",
      " 'ST': set(['12TH ST']),\n",
      " 'South': set(['Freedom Drive South',\n",
      "               'Grandview Drive South',\n",
      "               'Penn Circle South',\n",
      "               'Randolph Drive South']),\n",
      " 'Sq': set(['Elmer L Williams Sq',\n",
      "            'Harvard Sq',\n",
      "            'Northtowne Sq',\n",
      "            'Sheridan Sq']),\n",
      " 'St': set(['7th St',\n",
      "            '8th St',\n",
      "            'Bellefonte St',\n",
      "            'Castleman St',\n",
      "            'Copeland St',\n",
      "            'First St',\n",
      "            'Hemlock St',\n",
      "            'Henry St',\n",
      "            'Locust St',\n",
      "            'Main St',\n",
      "            'Mirror St',\n",
      "            'N Craig St',\n",
      "            'N Dithridge St',\n",
      "            'N Neville St',\n",
      "            'North Bellefield St',\n",
      "            'S Craig St',\n",
      "            'S Graham St',\n",
      "            'S Whitfield St',\n",
      "            'Saline St',\n",
      "            'South Craig St',\n",
      "            'South Dithridge St',\n",
      "            'Stanwix St',\n",
      "            'Walnut St',\n",
      "            'West St',\n",
      "            'Winthrop St',\n",
      "            'Wood St']),\n",
      " 'St.': set(['Atwood St.', 'Bryant St.', 'Byrant St.']),\n",
      " 'Strasse': set(['Rihn Strasse']),\n",
      " 'Ter': set(['Colby Ter', 'Faber Ter']),\n",
      " 'Trillium': set(['The Trillium']),\n",
      " 'Walnut': set(['Walnut']),\n",
      " 'Weir': set(['Weir']),\n",
      " 'West': set(['Deer Park Drive West',\n",
      "              'Horseshoe Circle West',\n",
      "              'Route 40 West',\n",
      "              'Waterfront Drive West',\n",
      "              'Waterman Road West']),\n",
      " 'Wheel-In-Campground': set(['Wheel-In-Campground']),\n",
      " 'center': set(['Hillcrest shopping center'])}\n"
     ]
    }
   ],
   "source": [
    "# Auditing our osm file\n",
    "st_types = audit(osm_file)\n",
    "\n",
    "# Printing results \n",
    "pprint.pprint(dict(st_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scrutinizing audit results I've built mapping of abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"ST\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Av.\": \"Avenue\",\n",
    "            \"Av\": \"Avenue\",\n",
    "            \"Sq\": \"Square\",\n",
    "            \"CT\": \"Court\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"DR\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Dr.\": \"Drive\", \n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"Ln\": \"Lane\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Brdg\":\"Bridge\",\n",
    "            \"Ter\": \"Terrace\" \n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now It's time to modify our osm file by replacement of abbreviations by full names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "osm_file_new = \"pittsburgh_pennsylvania_new.osm\"\n",
    "\n",
    "# This function replace abbrevition by full name in string\n",
    "def update_name(name, mapping):\n",
    "    words = name.split(' ')\n",
    "    last_word = words[-1]\n",
    "    if last_word in mapping.keys():\n",
    "        name2 = name.replace(last_word, mapping[last_word])\n",
    "        return name2\n",
    "    return name\n",
    "\n",
    "# Supporting function to get element from osm file\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "# This function replace abbreviations in osm file\n",
    "def modify(old_file, new_file):\n",
    "    with open(new_file, 'wb') as output:\n",
    "        output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        output.write('<osm>\\n  ') \n",
    "        for i, element in enumerate(get_element(old_file)):\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    tag.set('v',update_name(tag.attrib['v'], mapping))\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "        output.write('</osm>')\n",
    "\n",
    "# Modifying osm file\n",
    "modify(osm_file, osm_file_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database. To do so you will parse the elements in the OSM XML file, transforming them from document format to tabular format, thus making it possible to write to .csv files. These csv files can then easily be imported to a SQL database as tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to new csv files\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "# Re functions\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCH = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Importing schema for pransformation from schema.py file\n",
    "SCHEMA = Schema.schema\n",
    "\n",
    "# Fields of new csv files\n",
    "# Make sure the fields order in the csvs matches the column order in the \n",
    "# sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version',\n",
    "               'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "# Main function for transformation of XML data Python dict\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS,\n",
    "                  way_attr_fields=WAY_FIELDS, prob_ch=PROBLEMCH,\n",
    "                  default_tag_type='regular'):\n",
    "    \n",
    "    tag_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "    count = 0\n",
    "    if element.tag == 'node':\n",
    "        tagfields = node_attr_fields\n",
    "    elif element.tag == 'way':\n",
    "        tagfields = way_attr_fields\n",
    "    \n",
    "    if element.tag == 'node' or 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in tagfields:\n",
    "                tag_attribs[attrib] = element.attrib[attrib]\n",
    "    for subelem in element:\n",
    "        if subelem.tag == 'tag' and prob_ch.match(subelem.attrib['k']) == None:\n",
    "            tag = {}\n",
    "            tag['id'] = tag_attribs['id']\n",
    "            tag['value'] = subelem.attrib['v']\n",
    "            key = subelem.attrib['k']\n",
    "            tag['key'] = key[key.find(':') + 1:]\n",
    "            if ':' in key:\n",
    "                tag['type'] = key[:key.find(':')]\n",
    "            else:\n",
    "                tag['type'] = default_tag_type\n",
    "            tags.append(tag)\n",
    "        elif subelem.tag == 'nd':\n",
    "            way_node = {}\n",
    "            way_node['id'] = tag_attribs['id']\n",
    "            way_node['node_id'] = subelem.attrib['ref']\n",
    "            way_node['position'] = count\n",
    "            count += 1\n",
    "            way_nodes.append(way_node)\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        return {'node': tag_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': tag_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "# Validate element to match schema\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "# Extend csv.DictWriter to handle Unicode input\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "            \n",
    "# Main function to process osm file to 5 csv files\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "                    \n",
    "# Note: Validation is ~ 15X slower. Consider using a small\n",
    "# sample of the map when validating.\n",
    "process_map(osm_file_new, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build SQL database and import tables to this database from csv file from previous section. We'll use sqlite3 shell for this purpose. It's needed to read create_db.csv file.\n",
    ".read create_csv.db\n",
    "Next command will execute this file:\n",
    "\n",
    ".read create_csv.db\n",
    "\n",
    "Content of file:\n",
    "\n",
    "CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "\n",
    "\n",
    ".mode csv\n",
    "\n",
    ".import nodes.csv nodes\n",
    "\n",
    ".import ways.csv ways\n",
    "\n",
    ".import nodes_tags.csv nodes_tags\n",
    "\n",
    "delete from nodes_tags where id = 'id';\n",
    "\n",
    ".import ways_tags.csv ways_tags\n",
    "\n",
    "delete from ways_tags where id = 'id';\n",
    "\n",
    ".import ways_nodes.csv ways_nodes\n",
    "\n",
    "delete from ways_nodes where id = 'id';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quering SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quering database I'll use not sqlite3 shell, but sqlite3 Puthon API. \n",
    "\n",
    "1) Number of nodes\n",
    "\n",
    "2) Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1911654 nodes in database.\n",
      "There are 195498 ways in database.\n"
     ]
    }
   ],
   "source": [
    "# Importing SQLite3 API\n",
    "import sqlite3\n",
    "\n",
    "#Esteblishing connection and cursor\n",
    "conn = sqlite3.connect(\"osm.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Executing and printing \n",
    "cursor.execute(\"select count(id) from nodes;\")\n",
    "print 'There are {} nodes in database.'.format(cursor.fetchall()[0][0])\n",
    "cursor.execute(\"select count(id) from ways;\")\n",
    "print 'There are {} ways in database.'.format(cursor.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1227 uniqe users in database.\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"select count(distinct(uid)) from (select uid from nodes union select uid from ways);\")\n",
    "print 'There are {} uniqe users in database.'.format(cursor.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) Way with the biggest nodes count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There're 1975 nodes in the biggest way in database. Way id is 186341673.\n",
      "This way is:\n",
      "[(186341673, u'name', u'Breakneck Creek', u'regular\\r'),\n",
      " (186341673, u'source', u'bing', u'regular\\r'),\n",
      " (186341673, u'waterway', u'stream', u'regular\\r'),\n",
      " (186341673, u'city', u'Mars', u'addr\\r')]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"select id, count(*) as nodes_count from ways_nodes group by id order by nodes_count desc limit 1;\")\n",
    "way_id, count = cursor.fetchall()[0]\n",
    "print \"There're {} nodes in the biggest way in database. Way id is {}.\".format(count, way_id)\n",
    "cursor.execute(\"select * from ways_tags where id = {};\".format(way_id))\n",
    "print 'This way is:'\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "5) Number of bridges in Pittsburgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 410 bridges in Pitt. That's a second Venice.\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"select count(key) from ways_tags where key = 'bridge' and value != 'yes' group by key;\")\n",
    "print \"There are {} bridges in Pitt. That's a second Venice.\".format(cursor.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Top 5 zip codes in Pittsburgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'15206', 6653),\n",
      " (u'15044', 5333),\n",
      " (u'15025', 4950),\n",
      " (u'15216', 4853),\n",
      " (u'15017', 3454)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"select value, count(*) as count from nodes_tags where key = 'postcode' group by value order by count desc limit 5;\")\n",
    "pprint.pprint(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenStreetMap data is not perfect as any human modified project. It'll take a lot of time to find and clean all human-made errors. But we've made our first step. We modified street names and made them more consistent and uniform. Then we transformed XML to CSV format and imported it into SQL database. And finaly we answered some interesting questions using SQL queries. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
